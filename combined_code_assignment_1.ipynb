{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize # for word tokenization\n",
    "from nltk.tag import pos_tag # to get the part of speech for each token\n",
    "from nltk import RegexpParser #parse input for the pattern in the grammar string\n",
    "from nltk.corpus import wordnet #for finding stem word and noun lemmatization\n",
    "\n",
    "import random\n",
    "import re\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the user provided line and extract the Name token from it\n",
    "def GetName(sentence):\n",
    "    \n",
    "    #Parse either Proper Noun Singular or Noun because RegexpParser is inaccurate at times\n",
    "    grammar = 'NAME: {<NNP>*|<NN?>*}'\n",
    "    \n",
    "    #Create the Parser Object\n",
    "    cp = RegexpParser(grammar)\n",
    "    \n",
    "    common_words = {'hi', 'name', 'hello', 'thank', 'you', 'i', 'am', 'oh', 'hey', 'sure', 'yes', 'named', 'known'}\n",
    "    \n",
    "    #Tokenize the input\n",
    "    word_tokens = word_tokenize(sentence)\n",
    "    \n",
    "    #Eliminate the greeting words and get straight to discerning the Name as NNP or NN\n",
    "    word_tokens = [x for x in word_tokens if x.lower() not in common_words]\n",
    "    \n",
    "    #Obtain parts of speech for each token and run through parser\n",
    "    pos = pos_tag(word_tokens)\n",
    "    result = cp.parse(pos)\n",
    "    \n",
    "    #print statements for debugging \n",
    "    #print(result)\n",
    "    #result.draw()\n",
    "    \n",
    "    #Loop through the tree datastructure and pull the x (actual name), if the Root is 'NAME'\n",
    "    #we created for the result\n",
    "    \n",
    "    output = \"\" \n",
    "    for tree in result.subtrees():\n",
    "        if tree.label() == 'NAME':\n",
    "            name_match = ' '.join([x for x,y in tree.leaves()])\n",
    "            output = output + ' ' + name_match\n",
    "    \n",
    "    return output.replace(\"  \", \" \").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomize method simply takes a noun token and formats it is a response for followup using a \n",
    "#canned list, injecting the noun token appropriately for context\n",
    "def randomize(token, user_name):\n",
    "    \n",
    "    a1 = 'Why are you interested in ' + token + '?\\n'\n",
    "    a2 = 'Thanks for sharing about ' + token + '. Tell me more.\\n'\n",
    "    a3 = 'Why dont you tell me more about ' + token + '?\\n'\n",
    "    a4 = 'Most people relate to ' + token + ' in some form.  Why are you curious about it?\\n'\n",
    "    a5 = 'There is a lot of research about ' + token + '. Are you aware of it?\\n'\n",
    "    \n",
    "    #Create a list object with above values\n",
    "    Custom_fillers = [a1, a2, a3, a4, a5]\n",
    "    \n",
    "    if len(token) > 0:\n",
    "            return random.choice(Custom_fillers)\n",
    "    \n",
    "    #print('randomize is called')\n",
    "    Random_fillers = {'question': [user_name + \", that is a very interesting question. What made you ask that?\\n\", \n",
    "                    user_name + ', before I answer, can you give me your thoughts?\\n', \n",
    "                    user_name + ', that is a complicated question. Can you provide me some more details?\\n', \n",
    "                    'Hmm. Where do I begin?\\n'],\n",
    "                    'statement': ['How does that make you feel?\\n',\n",
    "                    'Why do you think that?\\n',\n",
    "                    'How long have you felt this way?\\n',\n",
    "                    'I find that extremely interesting. I would like to know why you feel this way.\\n',\n",
    "                    'Thanks for sharing that with me. Tell me more.\\n',\n",
    "                    'Do you feel in touch with your inner self?\\n',\n",
    "                    'Do you really believe that?\\n']}\n",
    "       \n",
    "    if user_text.strip().endswith(\"?\"):\n",
    "        return random.choice(Random_fillers[\"question\"])\n",
    "    else:\n",
    "        return random.choice(Random_fillers[\"statement\"])   \n",
    "\n",
    "    \n",
    "    #Return randomly one of the list values that includes token passed in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This method captures the main part of speech composed of verb, determinant, noun\n",
    "#This can then be used to form a question to the user with that phrase\n",
    "def GetVerbDetNounPhrase(sentence):\n",
    "    \n",
    "    #print('GetNounPhrase is called')\n",
    "    output = ''\n",
    "    \n",
    "    #Parse either Proper Noun Singular or Noun because RegexpParser is inaccurate at times    \n",
    "    grammar = 'DNP: {<(VB |VBP)><DT>?<NN>}'\n",
    "\n",
    "    #Create the Parser Object \n",
    "    cp = RegexpParser(grammar)\n",
    " \n",
    "    #Tokenize the input and get part of speech\n",
    "    pos = pos_tag(word_tokenize(sentence))\n",
    "    \n",
    "    result = cp.parse(pos)\n",
    "    \n",
    "    #result.draw()\n",
    "    #print(result)\n",
    "\n",
    "    #Loop through the tree datastructure and pull the values under DNP node\n",
    "    #we created for the result\n",
    "    for tree in result.subtrees():\n",
    "        if tree.label() == 'DNP':\n",
    "            name_match = ' '.join([x for x,y in tree.leaves()])\n",
    "            output = output + name_match\n",
    "    \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This method pulls Noun from the sentence and returns it\n",
    "def GetNounPhrase(sentence):\n",
    "    \n",
    "    #print('GetNounPhrase is called')\n",
    "    output = ''\n",
    "\n",
    "    #Parse either Proper Noun Singular or Noun because RegexpParser is inaccurate at times     \n",
    "    grammar = 'NP: {<DT>?<JJ>*<NN.*>+}'\n",
    " \n",
    "    #Create the Parser Object \n",
    "    cp = RegexpParser(grammar)\n",
    "    \n",
    "    #Tokenize the input and get part of speech\n",
    "    pos = pos_tag(word_tokenize(sentence))\n",
    "    \n",
    "    result = cp.parse(pos)\n",
    "\n",
    "    #for debugging    \n",
    "    #result.draw()    \n",
    "    #print(result)\n",
    "    \n",
    "    #Loop through the tree datastructure and pull the values under DNP node\n",
    "    #we created for the result \n",
    "    for subtree in result.subtrees(filter=lambda t: t.label() == 'NP'):\n",
    "        output = ' '.join(item[0] for item in subtree.leaves()) # 'abc\\nghi\\nmno'\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This method searches to see if there's a verb embedded somewhere in\n",
    "#in the sentence and tries to convert into a Noun form and return it\n",
    "def GetVerbPhrase(sentence):\n",
    "       \n",
    "    #print('GetNounPhrase is called')\n",
    "    output = ''\n",
    "    verb_token = ''\n",
    "\n",
    "    #Parse either Proper Noun Singular or Noun because RegexpParser is inaccurate at times    \n",
    "    grammar = 'VP: {<VB> | <VBP>}'\n",
    "\n",
    "    #Create the Parser Object     \n",
    "    cp = RegexpParser(grammar)\n",
    "    \n",
    "    #Tokenize the input and get part of speech  \n",
    "    pos = pos_tag(word_tokenize(sentence))\n",
    "    \n",
    "    result = cp.parse(pos)\n",
    "    \n",
    "    #Debug: look at the tree formed\n",
    "    #result.draw()\n",
    "    #print(result)\n",
    "\n",
    "    #Loop through the tree datastructure and pull the values under DNP node\n",
    "    #we created for the result  \n",
    "    for subtree in result.subtrees(filter=lambda t: t.label() == 'VP'):\n",
    "        verb_token = ' '.join(item[0] for item in subtree.leaves()) \n",
    "    \n",
    "    #print('verb found:' + verb_token)\n",
    "    misclassified_verbs  = ['is', 'are', 'am', 'do']\n",
    "    if verb_token in misclassified_verbs:\n",
    "        return ''; #if it is a verb that cannot be converted just return blank\n",
    "    \n",
    "    if (len(verb_token.strip()) == 0):\n",
    "        return verb_token.strip()  #if there's no verb just return blank\n",
    "\n",
    "    #Second half of the program\n",
    "    #Begin with creating a wordnet library object\n",
    "    wn = wordnet        \n",
    "    #debugging\n",
    "    #wl = WordNetLemmatizer()\n",
    "    #wn.lemma('give.v.01.give').derivationally_related_forms()\n",
    "\n",
    "    #Use try catch loop because some verbs do not have a noun form and result\n",
    "    #in exception error\n",
    "    try:\n",
    "        #create a lemma word of hte form verb + v.01 + verb => this is what wordnet lemma method takes\n",
    "        lemma_word = verb_token + '.v.01.' + verb_token\n",
    " \n",
    "        #debug to try\n",
    "        # wn.lemma('perform.v.01.perform').derivationally_related_forms()\n",
    "        \n",
    "        #Call the lemma function and then derivationally_related_forms() to get all the applicable\n",
    "        #word forms wordnet can give us\n",
    "        lemma_output = wn.lemma(lemma_word).derivationally_related_forms()\n",
    "        \n",
    "        #debug\n",
    "        #print(lemma_output)\n",
    "        \n",
    "        #if we find a noun form ending with ing, ial, ion we want it!\n",
    "        for x in lemma_output:\n",
    "            #print (x.name())\n",
    "            if (re.search(r'ing$|ial$|ion$', x.name())):\n",
    "                return x.name()\n",
    "  \n",
    "        #if its not one of the three above, return the first noun form found\n",
    "        output = lemma_output[0].name()\n",
    "    except:\n",
    "        output = ''\n",
    "        #Ideally handle the exception, in this case we return a blank\n",
    "        #print(\"Oops!\", sys.exc_info()[0], \"occurred.\")\n",
    "    \n",
    "    return output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As self-explanatory name suggests, convert the words so they are not misdiagnosed in parsing step\n",
    "def ConvertApostrophe(token):\n",
    "    # specific\n",
    "    token = re.sub(r\"won't\", \"will not\", token)\n",
    "    token = re.sub(r\"can\\'t\", \"can not\", token)\n",
    "    token = re.sub(r\"n\\'t\", \" not\", token)\n",
    "    token = re.sub(r\"\\'re\", \" are\", token)\n",
    "    token = re.sub(r\"\\'s\", \" is\", token)\n",
    "    token = re.sub(r\"\\'d\", \" would\", token)\n",
    "    token = re.sub(r\"\\'ll\", \" will\", token)\n",
    "    token = re.sub(r\"\\'t\", \" not\", token)\n",
    "    token = re.sub(r\"\\'ve\", \" have\", token)\n",
    "    token = re.sub(r\"\\'m\", \" am\", token)\n",
    "    return token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_name = \"\"  #name we want to extract from user input\n",
    "\n",
    "flag=True # Flag to break our loops processing user input\n",
    "\n",
    "#Debug\n",
    "#print('Jai Ganesh!')\n",
    "\n",
    "\n",
    "prompt = \"Hi, I'm a AIT 590 Psychotherapist. What is your name?\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Hi, I'm a AIT 590 Psychotherapist. What is your name?\n",
      " Matiullah\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    #Begin with welcome message after stripping the single quotes to form standard words\n",
    "    user_input = ConvertApostrophe(input(prompt))\n",
    "    \n",
    "    #User wants to quit, time to break the loop already\n",
    "    if (user_input.strip().lower() == 'quit' or user_input.strip().lower() == 'exit'):\n",
    "        flag = False\n",
    "        break\n",
    "    \n",
    "    if(user_input.strip() == ''):\n",
    "        prompt = \"Sorry couldn't get your name, can you try one more time?\"\n",
    "        continue  \n",
    "    else:\n",
    "        user_name = GetName(user_input)\n",
    "        prompt = 'Hi ' + user_name + '. You can type quit to end our conversation anytime. How can I help you today?\\n'\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Hi Matiullah. You can type quit to end our conversation anytime. How can I help you today?\n",
      " melaka\n",
      "Why are you interested in melaka?\n",
      " da\n",
      "Do you feel in touch with your inner self?\n",
      " quit\n"
     ]
    }
   ],
   "source": [
    "while(flag == True):\n",
    "    \n",
    "    user_text = input(prompt)\n",
    "    \n",
    "    if (len(user_text) == 0):\n",
    "        prompt = \"No input received, please try again\"\n",
    "        continue\n",
    "    #user_response=user_response.lower()\n",
    "    \n",
    "    #print('user text on line 275 is ' + user_text)\n",
    "    user_text = ConvertApostrophe(user_text)\n",
    "    if(user_text.strip().lower() =='quit' or user_text.strip().lower() == 'exit'):\n",
    "        flag=False\n",
    "        break\n",
    "    elif(re.search(r'\\byou\\b', user_text, re.IGNORECASE)):\n",
    "         prompt = user_name + \", thank you for that response. let's focus on you :) \\n\"\n",
    "         continue #if the question is for the chatbot, turn it around to the user\n",
    "    else:\n",
    "           \n",
    "        # ATTEMPT 1: Try the grammar format \"verb determinant noun\"\n",
    "        # for example, rule-the-world.\n",
    "        # If user enters \"I like to play the piano\", method should return \"play the piano\"\n",
    "        \n",
    "        user_response = GetVerbDetNounPhrase(user_text).strip()\n",
    " \n",
    "        #print(\"GetVerbDetNounPhrase returned\" + user_response) #debug      \n",
    "        if (len(user_response) > 2):\n",
    "            #Found a response, build the string for the next prompt\n",
    "            prompt = user_name + \", why do you want to \" + user_response + \"?\\n\"\n",
    "            continue #go back to the top of the while loop\n",
    "       \n",
    "        #ATTEMPT 2: Try the grammar format Noun first (with or without verb later)\n",
    "        user_response = GetNounPhrase(user_text).strip()\n",
    "        \n",
    "        #Debug\n",
    "        #print(\"GetNounPhrase returned\" + user_response)\n",
    "        if (len(user_response) > 2):\n",
    "            prompt = randomize(user_response, user_name)\n",
    "            continue;\n",
    "            \n",
    "        # ATTEMPT 3: Try the grammar format verb without a noun\n",
    "        # for example, deny.\n",
    "        # If user enters \"I like to play the piano\", method should return \"play the piano\"\n",
    "        \n",
    "        #try to capture the essential verb-det-noun, if not found, try just the verb\n",
    "        #I warn, the function returns warning\n",
    "        user_response = GetVerbPhrase(user_text).strip()\n",
    "        #print(\"GetVerbPhrase returned \" + user_response)\n",
    "        if (len(user_response) > 2):\n",
    "            prompt = user_name + \", \" + randomize(user_response, user_name)\n",
    "            continue\n",
    "        \n",
    "        #All 3 Attempts above did not result in us learning the context satisfactorily\n",
    "        #Try random responses\n",
    "  \n",
    "        prompt = randomize('', user_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good bye Matiullah. See you in your next appointment!\n"
     ]
    }
   ],
   "source": [
    "#User has indicated they want to quit\n",
    "print(\"Good bye \" + user_name + \". See you in your next appointment!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
